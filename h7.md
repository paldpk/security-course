x) Read and summarize 
Homework page: https://terokarvinen.com/trust-to-blockchain/#homework


<img width="946" alt="image" src="https://github.com/user-attachments/assets/a5085ca0-3a9c-40be-8ad2-332368bf6d2d">

I found the article published under the above category- A systematic review of artificial intelligence impact assessments
https://jfp.csc.fi/jufoportaali?Jufo_ID=51841
The article was quite long so my writing is based on skimming.
Data Collection Approach:
A multi-pronged method was used to identify relevant documents, including a systematic review of academic literature, internet searches, snowballing, peer input, and direct outreach to organizations. This process led to an initial pool of 181 documents, narrowed down to 38 based on strict inclusion criteria.

Inclusion and Exclusion Criteria:
Only documents explicitly designed as AI-IAs were included, focusing on those providing structured guidance for conducting assessments. Broader impact assessments or documents discussing AI-IAs without actionable guidance were excluded.

Heterogeneity of AI-IAs:
The final set of documents varied significantly in format, purpose, and origin, including academic publications, regulatory guidance, and organizational reports. They addressed various aspects of AI-IAs, such as purpose, scope, issues, processes, methods, transparency, and challenges.

Coding and Analysis Framework:
A thematic coding structure was developed and refined through team discussions to ensure consistency and accommodate new insights. The framework focused on key components of AI-IAs, such as benefits, ethical issues, and data protection, ensuring a comprehensive analysis of diverse documents.

AI-IAs are recommended at multiple stages of the AI lifecycle, including major project phases, significant system changes (e.g., data processes), and prior to production. Regular reassessments are advised, such as every few years or after substantial updates.

AI-IAs should be iterative and evolve based on new research, stakeholder feedback, and insights from the AI’s operational performance, ensuring assessments remain relevant and effective over time.
AI-IAs should address risks across short, medium, and long-term timeframes. Ideally, assessments should be conducted early in the AI lifecycle—before deployment, acquisition, or at the start of development for in-house projects.

Transparency as a Core Principle:
Transparency in AI systems involves making actions, processes, and data accessible, understandable, and open. This includes publishing project details in clear formats, explaining AI decisions, and potentially providing access to source code. Transparency enhances user autonomy by helping individuals understand and relate to automated decisions.

Key Elements of Trustworthy AI:
Trustworthy AI requires traceability, explainability, and open communication about limitations. These elements build confidence in AI systems by allowing stakeholders to examine models, data, decision-making processes, and the broader impacts of AI systems on individuals and society.

Challenges and Requirements for Transparency:
Lack of interpretability in AI decisions can frustrate users and expose organizations to risks. Transparency demands ongoing evaluations, public disclosures about automated systems, and robust auditing tools. Such practices must define and measure impacts, ensuring ethical and lawful use of AI.


Role of Auditing and Ethical Oversight:
Auditing processes should assess the equality of opportunities and outcomes, ensuring adjustments to mitigate adverse impacts. Auditors must adhere to ethical standards to enhance fairness and maintain accountability, contributing to a comprehensive evaluation of AI systems over time.


Another article  reviwed
Source used : https://www.researchgate.net/publication/381876656_AI-powered_Fraud_Detection_and_Risk_Management_in_the_Cloud
AI-powered Fraud Detection and Risk Management in the Cloud
The rapid growth of cloud computing and the adoption of digital services have significantly increased financial fraud and cybersecurity threats. Traditional systems often fail to keep up with these evolving threats, necessitating AI-powered fraud detection and risk management solutions.

Key Highlights:
Role of AI and Machine Learning (ML):

AI and ML techniques, including supervised (e.g., logistic regression, decision trees) and unsupervised learning (e.g., anomaly detection, clustering), enhance the detection of fraudulent activities.
Deep learning models like RNNs, CNNs, and GANs provide advanced capabilities to analyze transaction data and generate robust fraud detection insights.
Benefits of Cloud Computing:
Scalability and Elasticity: Cloud platforms can adjust resources based on data volume and processing needs.
Real-time Processing: Enables swift detection and response to fraud.
Cost Efficiency: Reduces the need for on-premise infrastructure.
Integration with Cloud Infrastructure:

Data Collection & Preprocessing: Leveraging diverse data sources and preparing them for model training.
Model Deployment: Using cloud-native architectures like microservices and serverless functions.
Continuous Monitoring: Ensuring models adapt to new fraud patterns.
Challenges and Considerations:

Data Privacy & Security: Ensuring compliance with regulations like GDPR and CCPA.
Model Explainability: Making AI decisions transparent to stakeholders.
Regulatory Compliance: Aligning solutions with industry standards.
Case Studies & Success Stories:

Highlighted increased fraud detection accuracy, reduced false positives, improved operational efficiency, and enhanced customer satisfaction.
Conclusion:
The paper emphasizes the critical role of AI-powered, cloud-based fraud detection in the digital age, recommending organizations adopt these solutions for better fraud prevention and risk management. Future advancements in technologies like federated learning and multi-modal data analysis could further enhance these capabilities.




