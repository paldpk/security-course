x) Read and summarize 
Homework page: https://terokarvinen.com/trust-to-blockchain/#homework


<img width="946" alt="image" src="https://github.com/user-attachments/assets/a5085ca0-3a9c-40be-8ad2-332368bf6d2d">

I found the article published under the above category- A systematic review of artificial intelligence impact assessments
https://jfp.csc.fi/jufoportaali?Jufo_ID=51841
The article was quite long so my writing is based on skimming.
Data Collection Approach:
A multi-pronged method was used to identify relevant documents, including a systematic review of academic literature, internet searches, snowballing, peer input, and direct outreach to organizations. This process led to an initial pool of 181 documents, narrowed down to 38 based on strict inclusion criteria.

Inclusion and Exclusion Criteria:
Only documents explicitly designed as AI-IAs were included, focusing on those providing structured guidance for conducting assessments. Broader impact assessments or documents discussing AI-IAs without actionable guidance were excluded.

Heterogeneity of AI-IAs:
The final set of documents varied significantly in format, purpose, and origin, including academic publications, regulatory guidance, and organizational reports. They addressed various aspects of AI-IAs, such as purpose, scope, issues, processes, methods, transparency, and challenges.

Coding and Analysis Framework:
A thematic coding structure was developed and refined through team discussions to ensure consistency and accommodate new insights. The framework focused on key components of AI-IAs, such as benefits, ethical issues, and data protection, ensuring a comprehensive analysis of diverse documents.

AI-IAs are recommended at multiple stages of the AI lifecycle, including major project phases, significant system changes (e.g., data processes), and prior to production. Regular reassessments are advised, such as every few years or after substantial updates.

AI-IAs should be iterative and evolve based on new research, stakeholder feedback, and insights from the AI’s operational performance, ensuring assessments remain relevant and effective over time.
AI-IAs should address risks across short, medium, and long-term timeframes. Ideally, assessments should be conducted early in the AI lifecycle—before deployment, acquisition, or at the start of development for in-house projects.

Transparency as a Core Principle:
Transparency in AI systems involves making actions, processes, and data accessible, understandable, and open. This includes publishing project details in clear formats, explaining AI decisions, and potentially providing access to source code. Transparency enhances user autonomy by helping individuals understand and relate to automated decisions.

Key Elements of Trustworthy AI:
Trustworthy AI requires traceability, explainability, and open communication about limitations. These elements build confidence in AI systems by allowing stakeholders to examine models, data, decision-making processes, and the broader impacts of AI systems on individuals and society.

Challenges and Requirements for Transparency:
Lack of interpretability in AI decisions can frustrate users and expose organizations to risks. Transparency demands ongoing evaluations, public disclosures about automated systems, and robust auditing tools. Such practices must define and measure impacts, ensuring ethical and lawful use of AI.


Role of Auditing and Ethical Oversight:
Auditing processes should assess the equality of opportunities and outcomes, ensuring adjustments to mitigate adverse impacts. Auditors must adhere to ethical standards to enhance fairness and maintain accountability, contributing to a comprehensive evaluation of AI systems over time.



